filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess <- ess %>%
filter(domain %in% pop$domain) # filter out areas not present in population dataset
ess_w_area <- ess %>%
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- ess %>%
left_join(ess_w_area, by = "domain") %>%    # merge sum of weights with ESS units
left_join(pop, by = "domain") %>%           # merge region population sizes
mutate(weight = pspwght * pweight,          # compute weights for cross-national analysis
weight = (weight * pop2016) / w_sum) # recalibrate weights to population sample size
dir <- direct(y       = ess$trstplc,
dom     = ess$area,
sweight = ess$weight,
domsize = pop[,2:3],
replace = FALSE)
summary(dir$Direct) # summary statistics of direct estimates
# produce boxplot of coefficients of variation
ggplot(dir, aes(x=Domain, y=CV)) +
geom_boxplot() +
ggtitle("Coefficient of Variation of direct estimates")
pop <- pop %>%
left_join(dir, by = c("area" = "Domain"))
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/covs_short.csv")
covs <- read.csv(text = URL)
pop <- pop %>%
left_join(covs, by = "domain") # merge covariates with direct estimates
View(pop)
pop %>%
dplyr::select(fem_p_16, gdp_eurhab_16, robb_r_10, burg_r_10, he_p_16, medage_16) %>%
summarise_all(funs(sum(is.na(.))))
pop %>%
dplyr::select(fem_p_16, gdp_eurhab_16, robb_r_10, burg_r_10, he_p_16, medage_16) %>%
summarise_all(funs(sum(is.na(.))))
library(Hmisc)
fun_imput <- aregImpute(~ fem_p_16 + gdp_eurhab_16 + robb_r_10 + burg_r_10 + he_p_16 + medage_16,
data = pop, n.impute = 10)
fun_imput$rsq
imputed <- as.data.frame(impute.transcan(fun_imput, imputation = 1,
rhsImp = "mean", data = pop,
list.out=T))
pop <- pop %>%
dplyr::select(domain, area, pop2016, SampSize, Direct, SD, CV) %>%
cbind(imputed)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop2 )
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
summary(model)
model$coefficients
(pretty_lm <- prettify(summary(model)))
install.packages("papeR")
library(papeR)
(pretty_lm <- prettify(summary(model)))
xtable(prettify(summary(model)))
pop <- pop %>%
mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)     *2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
xtable(prettify(summary(model)))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(tidyr)
library(dplyr)
library(papeR)
library(essurvey)
set_email("david.builgil@manchester.ac.uk")
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
library(RCurl)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/NUTS_lookup.csv")
lookup <- read.csv(text = URL)
ess <- ess%>%
left_join(lookup, by = c("region" = "nuts3")) %>%          # merge lookup into ESS dataset
rename(domain = nuts2) %>%                                 # rename NUTS2 variable
mutate(domain = as.character(domain),                      # convert NUTS2 into character
domain = ifelse(is.na(domain), region, domain)) %>% # copy NUTS1 data if no NUTS2 information
filter(!(domain == 99999))                                 # delete NAs
library(sae)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/population.csv")
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess <- ess %>%
filter(domain %in% pop$domain) # filter out areas not present in population dataset
ess_w_area <- ess %>%
filter(domain %in% pop$domain)
ess_w_area <- ess %>%
filter(domain %in% pop$domain) %>%
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
ess <- ess%>%
left_join(lookup, by = c("region" = "nuts3")) %>%          # merge lookup into ESS dataset
rename(domain = nuts2) %>%                                 # rename NUTS2 variable
mutate(domain = as.character(domain),                      # convert NUTS2 into character
domain = ifelse(is.na(domain), region, domain)) %>% # copy NUTS1 data if no NUTS2 information
filter(!(domain == 99999))                                 # delete NAs
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess_w_area <- ess %>%
filter(domain %in% pop$domain) %>%
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- ess %>%
filter(domain %in% pop$domain) # filter out areas not present in population dataset
ess_w_area <- ess %>%
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(tidyr)
library(dplyr)
library(papeR)
library(essurvey)
set_email("david.builgil@manchester.ac.uk")
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/NUTS_lookup.csv")
library(RCurl)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/NUTS_lookup.csv")
lookup <- read.csv(text = URL)
ess <- ess%>%
left_join(lookup, by = c("region" = "nuts3")) %>%          # merge lookup into ESS dataset
rename(domain = nuts2) %>%                                 # rename NUTS2 variable
mutate(domain = as.character(domain),                      # convert NUTS2 into character
domain = ifelse(is.na(domain), region, domain)) %>% # copy NUTS1 data if no NUTS2 information
filter(!(domain == 99999))                                 # delete NAs
library(sae)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/population.csv")
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess <- ess %>%
filter(domain %in% pop$domain) # filter out areas not present in population dataset
ess_w_area <- ess %>%
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
class(ess)
class(domain)
class(ess$domain)
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
sample_region <- ess %>%
filter(region != 99999) %>% # filter out NAs
group_by(region) %>%        # categories based on regions
summarize(n = n())          # calculate sample size
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(tidyr)
library(dplyr)
library(essurvey)
set_email("david.builgil@manchester.ac.uk")
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
summary(ess$trstplc)
trust_poli <- ess %>%
group_by(trstplc) %>%     # categories based on level of trust
summarize(n = n()) %>%    # number of respondents per group
mutate(prop = n / sum(n)) # proportion respondents per group
theme_set(theme_minimal()) # set white theme for plots
ggplot(data = trust_poli, aes(x = trstplc, y = prop)) + # set variables of interest
geom_bar(stat="identity") +                           # plot bar graph
ggtitle("Trust in police across European countries")  # change title
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
sample_region <- ess %>%
filter(region != 99999) %>% # filter out NAs
group_by(region) %>%        # categories based on regions
summarize(n = n())          # calculate sample size
summary(sample_region$n)
ess %>%
group_by(regunit, cntry) %>% # group by spatial scale and country
summarize(n = n())           # print sample size per country
library(RCurl)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/NUTS_lookup.csv")
lookup <- read.csv(text = URL)
ess <- ess%>%
left_join(lookup, by = c("region" = "nuts3")) %>%          # merge lookup into ESS dataset
rename(domain = nuts2) %>%                                 # rename NUTS2 variable
mutate(domain = as.character(domain),                      # convert NUTS2 into character
domain = ifelse(is.na(domain), region, domain)) %>% # copy NUTS1 data if no NUTS2 information
filter(!(domain == 99999))                                 # delete NAs
library(sae)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/population.csv")
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess_w_area <- ess %>%
filter(domain %in% pop$domain)          # filter out areas not present in population dataset
ess_w_area <- ess %>%
filter(domain %in% pop$domain) %>%      # filter out areas not present in population dataset
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- ess %>%
filter(domain %in% pop$domain) %>%          # filter out areas not present in population dataset
left_join(ess_w_area, by = "domain") %>%    # merge sum of weights with ESS units
left_join(pop, by = "domain") %>%           # merge region population sizes
mutate(weight = pspwght * pweight,          # compute weights for cross-national analysis
weight = (weight * pop2016) / w_sum) # recalibrate weights to population sample size
dir <- direct(y       = ess$trstplc,
dom     = ess$area,
sweight = ess$weight,
domsize = pop[,2:3],
replace = FALSE)
View(dir)
summary(dir$Direct) # summary statistics of direct estimates
# produce boxplot of coefficients of variation
ggplot(dir, aes(x=Domain, y=CV)) +
geom_boxplot() +
ggtitle("Coefficient of Variation of direct estimates")
pop <- pop %>%
left_join(dir, by = c("area" = "Domain"))
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/covs_short.csv")
covs <- read.csv(text = URL)
pop <- pop %>%
left_join(covs, by = "domain") # merge covariates with direct estimates
pop %>%
dplyr::select(fem_p_16, gdp_eurhab_16, robb_r_10, burg_r_10, he_p_16, medage_16) %>%
summarise_all(funs(sum(is.na(.))))
library(Hmisc)
fun_imput <- aregImpute(~ fem_p_16 + gdp_eurhab_16 + robb_r_10 + burg_r_10 + he_p_16 + medage_16,
data = pop, n.impute = 10)
fun_imput <- aregImpute(~ fem_p_16 + gdp_eurhab_16 + robb_r_10 + burg_r_10 + he_p_16 + medage_16,
data = pop, n.impute = 10)
imputed <- as.data.frame(impute.transcan(fun_imput, imputation = 1,
rhsImp = "mean", data = pop,
list.out = T))
pop <- pop %>%
dplyr::select(domain, area, pop2016, SampSize, Direct, SD, CV) %>%
cbind(imputed)
pop <- pop %>%
mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)     *2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
summary(model)
pop_st <- pop %>%
mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)     *2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
View(pop_st)
pop_st <- pop %>%
dplyr::mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)     *2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
mean(fem_p_16)
mean(pop$fem_p_16)
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/population.csv")
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess_w_area <- ess %>%
filter(domain %in% pop$domain) %>%        # filter out areas not present in population dataset
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- ess %>%
filter(domain %in% pop$domain) %>%          # filter out areas not present in population dataset
left_join(ess_w_area, by = "domain") %>%    # merge sum of weights with ESS units
left_join(pop, by = "domain") %>%           # merge region population sizes
mutate(weight = pspwght * pweight,          # compute weights for cross-national analysis
weight = (weight * pop2016) / w_sum) # recalibrate weights to population sample size
View(pop)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
library(sf)
library(tidyr)
library(dplyr)
library(essurvey)
set_email("david.builgil@manchester.ac.uk")
ess <- import_rounds(rounds = 8, ess_email = NULL, format = NULL)
trust_poli <- ess %>%
group_by(trstplc) %>%     # categories based on level of trust
summarize(n = n()) %>%    # number of respondents per group
mutate(prop = n / sum(n)) # proportion respondents per group
theme_set(theme_minimal()) # set white theme for plots
ggplot(data = trust_poli, aes(x = trstplc, y = prop)) + # set variables of interest
geom_bar(stat="identity") +                           # plot bar graph
ggtitle("Trust in police across European countries")  # change title
ess <- ess %>%
# if trust is above or equal to mean, 1, 0
mutate(trstplc = ifelse(trstplc >= mean(trstplc, na.rm = T), 1, 0)) %>%
filter(!is.na(trstplc)) # delete NAs
sample_region <- ess %>%
filter(region != 99999) %>% # filter out NAs
group_by(region) %>%        # categories based on regions
summarize(n = n())          # calculate sample size
sample_region <- ess %>%
filter(region != 99999) %>% # filter out NAs
group_by(region) %>%        # categories based on regions
summarize(n = n())          # calculate sample size
summary(sample_region$n)
ess %>%
group_by(regunit, cntry) %>% # group by spatial scale and country
summarize(n = n())           # print sample size per country
library(RCurl)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/NUTS_lookup.csv")
lookup <- read.csv(text = URL)
ess <- ess%>%
left_join(lookup, by = c("region" = "nuts3")) %>%          # merge lookup into ESS dataset
rename(domain = nuts2) %>%                                 # rename NUTS2 variable
mutate(domain = as.character(domain),                      # convert NUTS2 into character
domain = ifelse(is.na(domain), region, domain)) %>% # copy NUTS1 data if no NUTS2 information
filter(!(domain == 99999))                                 # delete NAs
library(sae)
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/population.csv")
pop <- read.csv(text = URL)
pop <- pop %>%
mutate(area = 1:n()) %>%                 # create numeric id value
rename("domain" = "X.U.FEFF.domain") %>% # rename region column name
subset(select = c(1, 3, 2)) %>%          # reorder columns
filter(domain %in% ess$domain)           # filter out areas not present in ESS
ess_w_area <- ess %>%
filter(domain %in% pop$domain) %>%        # filter out areas not present in population dataset
group_by(domain) %>%                      # create groups by region
summarise(w_sum = sum(pspwght * pweight)) # sum weights per region
ess <- ess %>%
filter(domain %in% pop$domain) %>%          # filter out areas not present in population dataset
left_join(ess_w_area, by = "domain") %>%    # merge sum of weights with ESS units
left_join(pop, by = "domain") %>%           # merge region population sizes
mutate(weight = pspwght * pweight,          # compute weights for cross-national analysis
weight = (weight * pop2016) / w_sum) # recalibrate weights to population sample size
dir <- direct(y       = ess$trstplc,
dom     = ess$area,
sweight = ess$weight,
domsize = pop[,2:3],
replace = FALSE)
summary(dir$Direct) # summary statistics of direct estimates
# produce boxplot of coefficients of variation
ggplot(dir, aes(x=Domain, y=CV)) +
geom_boxplot() +
ggtitle("Coefficient of Variation of direct estimates")
pop <- pop %>%
left_join(dir, by = c("area" = "Domain"))
URL <- getURL("https://raw.githubusercontent.com/davidbuilgil/SAE_chapter/master/data/covs_short.csv")
covs <- read.csv(text = URL)
pop <- pop %>%
left_join(covs, by = "domain") # merge covariates with direct estimates
pop %>%
dplyr::select(fem_p_16, gdp_eurhab_16, robb_r_10, burg_r_10, he_p_16, medage_16) %>%
summarise_all(funs(sum(is.na(.))))
library(Hmisc)
fun_imput <- aregImpute(~ fem_p_16 + gdp_eurhab_16 + robb_r_10 + burg_r_10 + he_p_16 + medage_16,
data = pop, n.impute = 10)
imputed <- as.data.frame(impute.transcan(fun_imput, imputation = 1,
rhsImp = "mean", data = pop,
list.out = T))
View(imputed)
pop <- pop %>%
dplyr::select(domain, area, pop2016, SampSize, Direct, SD, CV) %>%
cbind(imputed)
pop_st <- pop %>%
mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)     *2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
View(pop_st)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
summary(model)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop_st)
summary(model)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop_st)
summary(model)
pop_st <- pop %>%
mutate(fem_p_16      = (fem_p_16      - mean(fem_p_16)      / sd(fem_p_16)*2),
gdp_eurhab_16 = (gdp_eurhab_16 - mean(gdp_eurhab_16) / sd(gdp_eurhab_16)*2),
robb_r_10     = (robb_r_10     - mean(robb_r_10)     / sd(robb_r_10)    *2),
burg_r_10     = (burg_r_10     - mean(burg_r_10)     / sd(burg_r_10)    *2),
medage_16     = (medage_16     - mean(medage_16)     / sd(medage_16)    *2),
he_p_16       = (he_p_16       - mean(he_p_16)       / sd(he_p_16)      *2))
model <- lm(Direct*100 ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop_st)
summary(model)
install.packages("QuantPsyc")
library(QuantPsyc)
model <- lm.beta(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop_st)
model <- lm.beta(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
pop_st)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
model.sc <- lm.beta(model)
summary(model.sc)
model.sc
model <- lm(scale(Direct) ~  scale(fem_p_16)  + scale(gdp_eurhab_16) + scale(robb_r_10) +
scale(burg_r_10) +  scale(medage_16)    + scale(he_p_16),
data = pop)
library(papeR)
xtable(prettify(summary(model)))
?xtable
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
model.sc <- lm(scale(Direct) ~  scale(fem_p_16)  + scale(gdp_eurhab_16) + scale(robb_r_10) +
scale(burg_r_10) +  scale(medage_16)    + scale(he_p_16),
data = pop)
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
xtable(prettify(summary(model.sc)), header = "Area-level model of trust in the police (standadized coefficients)")
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
View(model.sc)
model.sc$coefficients
names(model.sc$coefficients) <- c('(Intercept)' , 'Proportion females', 'GDP per person (€)',
'Robbery rate', 'Burglary rate'     , 'Median age',
'Proportion with HE')
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
model.sc <- lm(scale(Direct) ~  scale(fem_p_16)  + scale(gdp_eurhab_16) + scale(robb_r_10) +
scale(burg_r_10) +  scale(medage_16)    + scale(he_p_16),
data = pop)
names(model.sc$coefficients) <- c('(Intercept)' , 'Proportion females', 'GDP per person (€)',
'Robbery rate', 'Burglary rate'     , 'Median age',
'Proportion HE')
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
x <- xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
print(x)
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
summary(model)
model <- lm(Direct ~  fem_p_16  + gdp_eurhab_16 + robb_r_10 +
burg_r_10 +  medage_16    + he_p_16,
data = pop)
summary(model)
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
summary(model.sc)
r2(model)
R2(model)
rsq(model)
summary(model)$r.squared
summary(model)$p.value
summary(model)$p-value
x <- summary(model)
x$cov.unscaled
x$terms
x$coefficients
x$aliased
x$sigma
x$fstatistic
summary(model)
model.sc <- lm(scale(Direct) ~  scale(fem_p_16)  + scale(gdp_eurhab_16) + scale(robb_r_10) +
scale(burg_r_10) +  scale(medage_16)    + scale(he_p_16),
data = pop)
summary(model.sc)
names(model.sc$coefficients) <- c('(Intercept)' , 'Proportion females', 'GDP per person (€)',
'Robbery rate', 'Burglary rate'     , 'Median age',
'Proportion HE')
xtable(prettify(summary(model.sc)), caption = "Area-level model of trust in the police (standadized coefficients)")
